{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import ops\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from config import Config\n",
    "from model import MaskRCNN\n",
    "from acne_data import AcneSegDataset, transforms, expand_mask, seg_to_mask\n",
    "import visualize\n",
    "import utils\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "MODEL_PATH = 'run/resnet101_all_epoch_160.pth'\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 背景 丘疹 痣 节结\n",
    "# 开口粉刺 闭口粉刺\n",
    "# 萎缩性瘢痕 肥厚性瘢痕\n",
    "# 黄褐斑 脓疱 其它\n",
    "categories = ['BG', 'papule', 'nevus', 'nodule',\n",
    "              'open_comedo', 'closed_comedo',\n",
    "              'atrophic_scar', 'hypertrophic_scar',\n",
    "              'melasma', 'pustule', 'other']\n",
    "category_to_id = {c: i for i, c in enumerate(categories)}\n",
    "\n",
    "cfg = Config()\n",
    "dataset = AcneSegDataset(os.path.join(cfg.DATA_BASE_DIR, 'test_patch'),\n",
    "                         os.path.join(cfg.DATA_BASE_DIR, 'annotations', 'acne_test.json'),\n",
    "                         'test', cfg, transforms(cfg.RGB_MEAN, cfg.RGB_STD, cfg.IMAGE_SHAPE[:2], 'test'))\n",
    "\n",
    "mrcnn = MaskRCNN(cfg)\n",
    "mrcnn = mrcnn.to(DEVICE)\n",
    "utils.load_weights(mrcnn, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(model, images, config):\n",
    "    model.eval()\n",
    "    images = images.to(DEVICE)\n",
    "\n",
    "    bs = images.size(0)\n",
    "    detections, masks = model([images])\n",
    "    bboxes, class_ids, scores = detections[:, :, :4], detections[:, :, 4].long(), detections[:, :, 5]\n",
    "\n",
    "    pred_class_ids = []\n",
    "    pred_scores = []\n",
    "    pred_bboxes = []\n",
    "    pred_masks = []\n",
    "    for i in range(bs):\n",
    "        # Filter out background\n",
    "        idx = torch.nonzero(class_ids[i])[:, 0]\n",
    "        b_class_ids = class_ids[i, idx]\n",
    "        b_scores = scores[i, idx]\n",
    "        b_bboxes = bboxes[i, idx]\n",
    "        b_masks = masks[i, idx, b_class_ids]\n",
    "\n",
    "        b_bboxes[:, [0, 2]] *= config.IMAGE_SHAPE[0]\n",
    "        b_bboxes[:, [1, 3]] *= config.IMAGE_SHAPE[1]\n",
    "        b_bboxes = utils.clip_boxes(b_bboxes, [0, 0, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1]])\n",
    "        b_bboxes = b_bboxes.round()\n",
    "\n",
    "        # Filter out detections with zero area. Often only happens in early\n",
    "        # stages of training when the network weights are still a bit random.\n",
    "        areas = (b_bboxes[:, 2] - b_bboxes[:, 0]) * (b_bboxes[:, 3] - b_bboxes[:, 1])\n",
    "        idx = torch.nonzero(areas > 0)[:, 0]\n",
    "        b_class_ids = b_class_ids[idx]\n",
    "        b_scores = b_scores[idx]\n",
    "        b_bboxes = b_bboxes[idx]\n",
    "        b_masks = b_masks[idx]\n",
    "\n",
    "        pred_class_ids.append(b_class_ids.int().cpu().numpy())\n",
    "        pred_scores.append(b_scores.cpu().numpy())\n",
    "        pred_bboxes.append(b_bboxes.cpu().numpy())\n",
    "        pred_masks.append(b_masks.cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "    return pred_class_ids, pred_scores, pred_bboxes, pred_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(dataset) - 1)\n",
    "image, img_id = dataset[idx]\n",
    "pred_class_ids, pred_scores, pred_bboxes, pred_masks = infer(mrcnn, image.unsqueeze(0), cfg)\n",
    "if cfg.USE_MINI_MASK:\n",
    "    refind_masks = np.zeros((cfg.IMAGE_SHAPE[0], cfg.IMAGE_SHAPE[1], len(pred_class_ids[0])))\n",
    "    for i in range(len(pred_class_ids[0])):\n",
    "        refind_masks[:, :, i] = expand_mask(pred_bboxes[0][i], pred_masks[0][:, :, i], cfg.IMAGE_SHAPE[:2])\n",
    "    pred_masks = refind_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = image.numpy().transpose((1, 2, 0))\n",
    "image = np.clip(((image * cfg.RGB_STD) + cfg.RGB_MEAN) * 255, 0, 255).astype(np.int32)\n",
    "\n",
    "img_obj = dataset.coco.imgs[img_id]\n",
    "anns = dataset.coco.imgToAnns[img_id]\n",
    "\n",
    "gt_class_ids = np.zeros((len(anns),), dtype=int)\n",
    "gt_bboxes = np.zeros((len(anns), 4))\n",
    "gt_masks = np.zeros((cfg.IMAGE_SHAPE[0], cfg.IMAGE_SHAPE[1], len(anns)))\n",
    "for i, ann in enumerate(anns):\n",
    "    gt_class_ids[i] = ann['category_id']\n",
    "    bbox = ann['bbox']\n",
    "    gt_bboxes[i, :] = np.round(np.array([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]))\n",
    "    gt_masks[:, :, i] = seg_to_mask(ann['segmentation'], cfg.IMAGE_SHAPE[0], cfg.IMAGE_SHAPE[1])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10), dpi=150)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "visualize.display_instances(image, gt_bboxes, gt_masks, gt_class_ids, categories, ax=ax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10), dpi=150)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "visualize.display_instances(image, pred_bboxes[0], pred_masks, pred_class_ids[0], categories, pred_scores[0], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "coco = COCO(os.path.join(cfg.DATA_BASE_DIR, 'annotations', 'acne_train.json'))\n",
    "img_id = random.choice(coco.getImgIds())\n",
    "img_obj = coco.imgs[img_id]\n",
    "anns = coco.imgToAnns[img_id]\n",
    "\n",
    "image = io.imread(os.path.join(cfg.DATA_BASE_DIR, 'images', img_obj['file_name']))\n",
    "win_gen = utils.WindowGenerator(img_obj['height'], img_obj['width'], cfg.INFER_WINDOW_SIZE[0], cfg.INFER_WINDOW_SIZE[1], cfg.INFER_WINDOW_STRIDES[0], cfg.INFER_WINDOW_STRIDES[1])\n",
    "img_patches = []\n",
    "windows = []\n",
    "for slice_h, slice_w in win_gen:\n",
    "    img_patch = image[slice_h, slice_w, :]\n",
    "    img_patch = img_patch.astype(np.float32) / 255.0\n",
    "    img_patch = (img_patch - cfg.RGB_MEAN) / cfg.RGB_STD\n",
    "    img_patches.append(torch.tensor(img_patch.transpose((2, 0, 1)).copy()).float())\n",
    "    windows.append([slice_w.start, slice_h.start, slice_w.stop, slice_h.stop])\n",
    "img_patches = torch.stack(img_patches, dim=0)\n",
    "\n",
    "gt_class_ids = np.zeros((len(anns),), dtype=int)\n",
    "gt_bboxes = np.zeros((len(anns), 4))\n",
    "gt_masks = np.zeros((img_obj['height'], img_obj['width'], len(anns)))\n",
    "for i, ann in enumerate(anns):\n",
    "    gt_class_ids[i] = ann['category_id']\n",
    "    bbox = ann['bbox']\n",
    "    gt_bboxes[i, :] = np.round(np.array([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]))\n",
    "    gt_masks[:, :, i] = seg_to_mask(ann['segmentation'], img_obj['height'], img_obj['width'])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 16), dpi=150)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "visualize.display_instances(image, gt_bboxes, gt_masks, gt_class_ids, categories, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_class_ids, pred_scores, pred_bboxes, pred_masks = infer(mrcnn, img_patches, cfg)\n",
    "\n",
    "for i, bboxes in enumerate(pred_bboxes):\n",
    "    win = windows[i]\n",
    "    bboxes[:, [0, 2]] += win[0]\n",
    "    bboxes[:, [1, 3]] += win[1]\n",
    "\n",
    "pred_class_ids = np.concatenate(pred_class_ids, axis=0)\n",
    "pred_scores = np.concatenate(pred_scores, axis=0)\n",
    "pred_bboxes = np.concatenate(pred_bboxes, axis=0)\n",
    "pred_masks = np.concatenate(pred_masks, axis=2)\n",
    "\n",
    "keep = ops.nms(torch.tensor(pred_bboxes), torch.tensor(pred_scores), 0.3)\n",
    "keep = keep.numpy()\n",
    "pred_class_ids = pred_class_ids[keep]\n",
    "pred_scores = pred_scores[keep]\n",
    "pred_bboxes = pred_bboxes[keep]\n",
    "pred_masks = pred_masks[keep]\n",
    "\n",
    "if cfg.USE_MINI_MASK:\n",
    "    refind_masks = np.zeros((img_obj['height'], img_obj['width'], len(pred_class_ids)))\n",
    "    for i in range(len(pred_class_ids)):\n",
    "        refind_masks[:, :, i] = expand_mask(pred_bboxes[i], pred_masks[:, :, i], [img_obj['height'], img_obj['width']])\n",
    "    pred_masks = refind_masks\n",
    "\n",
    "fig = plt.figure(figsize=(12, 16), dpi=150)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "visualize.display_instances(image, pred_bboxes, pred_masks, pred_class_ids, categories, pred_scores, ax=ax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
